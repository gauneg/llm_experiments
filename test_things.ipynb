{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauneg/anaconda3/envs/torch_test/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "import ast\n",
    "import torch\n",
    "import numpy as np\n",
    "# from data_loader_asp import get_dataset, AspectDataset, AspectDatasetTrainer\n",
    "# from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForSeq2SeqLM, \\\n",
    "# Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "# from torch.utils.data import DataLoader\n",
    "# import evaluate\n",
    "# from typing import Dict, List, Optional\n",
    "# from dataclasses import dataclass, field\n",
    "# from self_eval import calc_labs\n",
    "\n",
    "# FILE_PATH = './restaurant_df.csv'\n",
    "# dataset =  pd.read_csv(FILE_PATH).sample(frac=1).reset_index(drop=True)\n",
    "# # asp_dset = AspectDataset(dataset,tokenizer)\n",
    "# dataset = dataset.values\n",
    "# val_split = 0.2\n",
    "\n",
    "# INDEX_SPLIT = dataset.shape[0] - int(val_split * dataset.shape[0])\n",
    "# TRAIN_DATASET = dataset[:INDEX_SPLIT, :]\n",
    "# VALID_DATASET = dataset[INDEX_SPLIT:, :]\n",
    "\n",
    "# datadict = {\"train\": TRAIN_DATASET, \"validation\": VALID_DATASET}\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base', max_model_lenght=512)\n",
    "\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = get_dataset(tokenizer, 'train')\n",
    "validation_dset = get_dataset(tokenizer, 'validation')\n",
    "\n",
    "model_dir = \"./t5_trainer\"\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", \n",
    "optim='adafactor', \n",
    "num_train_epochs=4,\n",
    "logging_strategy='steps',\n",
    "learning_rate=3e-4,\n",
    "logging_steps=100,\n",
    " save_strategy='epoch',\n",
    " per_device_train_batch_size=2,\n",
    " gradient_accumulation_steps=4\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "exact_match_metric = load('exact_match')\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "      # print(inputs.keys())\n",
    "      input_ids = inputs['input_ids']\n",
    "      labels = inputs['labels'] \n",
    "      attention_mask = inputs['attention_mask']\n",
    "      outputs = model(input_ids=input_ids, labels=labels, attention_mask=attention_mask)\n",
    "      return (outputs[\"loss\"], outputs[\"logits\"]) if return_outputs else outputs[\"loss\"]\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#   logits, labels = eval_pred\n",
    "#   predictions = torch.argmax(logits, axis=-1)\n",
    "#   pred_str = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(predictions, skip_special_tokens=True))\n",
    "#   true_str = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(labels, skip_special_tokens=True))\n",
    "#   pred_arr = [word for word in pred_str.split(',') if word.lower()!='null']\n",
    "#   true_arr = [word for word in true_arr.split(',') if word.lower()!='null']\n",
    "#   return exact_match_metric(predictions=pred_arr, references=true_arr)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dset,\n",
    "    # eval_dataset=validation_dset,\n",
    "    # compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1600\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 1600\n",
      "  Number of trainable parameters = 247577856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1600' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1600/1600 43:16, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test_trainer/checkpoint-200\n",
      "Configuration saved in test_trainer/checkpoint-200/config.json\n",
      "Configuration saved in test_trainer/checkpoint-200/generation_config.json\n",
      "Model weights saved in test_trainer/checkpoint-200/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-400\n",
      "Configuration saved in test_trainer/checkpoint-400/config.json\n",
      "Configuration saved in test_trainer/checkpoint-400/generation_config.json\n",
      "Model weights saved in test_trainer/checkpoint-400/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-600\n",
      "Configuration saved in test_trainer/checkpoint-600/config.json\n",
      "Configuration saved in test_trainer/checkpoint-600/generation_config.json\n",
      "Model weights saved in test_trainer/checkpoint-600/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-800\n",
      "Configuration saved in test_trainer/checkpoint-800/config.json\n",
      "Configuration saved in test_trainer/checkpoint-800/generation_config.json\n",
      "Model weights saved in test_trainer/checkpoint-800/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-1000\n",
      "Configuration saved in test_trainer/checkpoint-1000/config.json\n",
      "Configuration saved in test_trainer/checkpoint-1000/generation_config.json\n",
      "Model weights saved in test_trainer/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-1200\n",
      "Configuration saved in test_trainer/checkpoint-1200/config.json\n",
      "Configuration saved in test_trainer/checkpoint-1200/generation_config.json\n",
      "Model weights saved in test_trainer/checkpoint-1200/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-1400\n",
      "Configuration saved in test_trainer/checkpoint-1400/config.json\n",
      "Configuration saved in test_trainer/checkpoint-1400/generation_config.json\n",
      "Model weights saved in test_trainer/checkpoint-1400/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-1600\n",
      "Configuration saved in test_trainer/checkpoint-1600/config.json\n",
      "Configuration saved in test_trainer/checkpoint-1600/generation_config.json\n",
      "Model weights saved in test_trainer/checkpoint-1600/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1600, training_loss=0.12678282912587746, metrics={'train_runtime': 2598.5848, 'train_samples_per_second': 4.926, 'train_steps_per_second': 0.616, 'total_flos': 8764894111334400.0, 'train_loss': 0.12678282912587746, 'epoch': 8.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_dload = DataLoader(validation_dset, batch_size=16)\n",
    "from self_eval import calc_labs\n",
    "fin_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "/home/gauneg/anaconda3/envs/torch_test/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dpoint in v_dload:\n",
    "    inp_ids = dpoint['input_ids']\n",
    "    labels = dpoint['labels']\n",
    "    amask = dpoint['attention_mask']\n",
    "    y_pred = model.generate(inp_ids.to(model.device))\n",
    "    for x, y, y_true in zip(inp_ids,y_pred, labels):\n",
    "        pred = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(y, skip_special_tokens=True))\n",
    "        refs = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(y_true, skip_special_tokens=True))\n",
    "        pred_arr = [y.strip().lower() for y in pred.split(',') if y.strip().lower()!='null']\n",
    "        refs_arr = [y.strip().lower() for y in refs.split(',') if y.strip().lower()!='null']\n",
    "        fin_arr.append([pred_arr, refs_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7381546134663342, recall: 0.7493670886075949, f1:0.7437185929648241\n"
     ]
    }
   ],
   "source": [
    "calc_labs(fin_arr)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flan-T5 results without prompts\n",
    "#### RESULTS WITH FLAN-T5-Small batch size 8, nsteps=800, gradient_accumulation_steps=1\n",
    "`precision: 0.671604938271605, recall: 0.649164677804296, f1:0.6601941747572817`\n",
    "\n",
    "#### RESULTS WITH FLAN-T5-BASE batch size 2, nsteps=800, gradient_accumulation_steps=4\n",
    "`precision: 0.765, recall: 0.7409200968523002, f1:0.7527675276752769`\n",
    "\n",
    "## FLAN-T5-BASE NO PROMPT\n",
    "### MAMS \n",
    "`(0.7493806771263418, 0.8153638814016172, 0.7809810671256453)`\n",
    "### Laptops 2014\n",
    "`(0.3110938712179985, 0.39007782101167315, 0.3461372464393613)`\n",
    "### Restaurant 2014\n",
    "`0.591321243523316, 0.6880180859080633, 0.6360153256704981`\n",
    "\n",
    "## FLAN-T5-BASE results with the following prompt \n",
    "find the aspect term in the text\n",
    "\n",
    "### MAMS \n",
    "`0.7437268613739202, 0.8122192273135669, 0.7764655357526303`\n",
    "\n",
    "### Laptops 2014\n",
    "`0.25784615384615384, 0.4075875486381323, 0.31586882774217867`\n",
    "\n",
    "### Restaurant 2014\n",
    "`0.5540540540540541, 0.7106254709871892, 0.6226477385275668`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "yx = model.generate(inputs=train_dset[1]['input_ids'].unsqueeze(dim=0), )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_train1 = '/home/gauneg/llm_experiments/ds_for_generation/restaurant_train_mams_gen.csv'\n",
    "restaurant_train2 = '/home/gauneg/llm_experiments/ds_for_generation/dep_restaurant_rule_gen_14.csv'\n",
    "df_train_restaurant1 = pd.read_csv(restaurant_train1)\n",
    "df_train_restaurant2 = pd.read_csv(restaurant_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_values = np.vstack((df_train_restaurant1.values, df_train_restaurant2.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(combined_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['but the staff was so horrible to us.',\n",
       "        \"[('staff', None), ('staff', None)]\"],\n",
       "       [\"to be completely fair, the only redeeming factor was the food, which was above average, but couldn't make up for all the other deficiencies of teodora.\",\n",
       "        \"[('teodora', None), ('food', None)]\"],\n",
       "       [\"the food is uniformly exceptional, with a very capable kitchen which will proudly whip up whatever you feel like eating, whether it's on the menu or not.\",\n",
       "        \"[('kitchen', None), ('menu', None), ('food', None)]\"],\n",
       "       ...,\n",
       "       ['When we arrived at 6:00 PM, the restaurant was practically empty.',\n",
       "        \"[('restaurant', None)]\"],\n",
       "       ['Each table has a pot of boiling water sunken into its surface, and you get platters of thin sliced meats, various vegetables, and rice and glass noodles.',\n",
       "        \"[('glass noodles', None), ('various vegetables', None), ('rice', None), ('platters', None), ('thin sliced meats', None)]\"],\n",
       "       ['I am going to the mid town location next.',\n",
       "        \"[('mid town location', None)]\"]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['We went here for lunch a couple of weeks ago on a Saturday, and I was thoroughly impressed with the food.',\n",
       "        \"[('food', None)]\"],\n",
       "       ['my picks: Guizhou chicken, fish with hot bean source, fish fillet in spicy source (special menu).',\n",
       "        \"[('fish fillet', None), ('special menu', None), ('spicy source', None), ('bean source', None)]\"],\n",
       "       ['We walked in on a Wednesday night and were seated promptly.',\n",
       "        '[]'],\n",
       "       ...,\n",
       "       [\"In fact, you can't miss it.\", \"[('fact', None)]\"],\n",
       "       ['I have been about 4 times and have always had a great meal.',\n",
       "        \"[('meal', None)]\"],\n",
       "       ['Excellent experience.', \"[('experience', None)]\"]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAMS_PATH = '/home/gauneg/llm_experiments/mams_atsa_train.csv'\n",
    "DEP_GENERATED_LAPTOP = '/home/gauneg/llm_experiments/ds_for_generation/dep_laptop_rule_gen_14.csv'\n",
    "MAMS_GENRATED_LAPTOP = '/home/gauneg/llm_experiments/ds_for_generation/laptop_train_mams_gen.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mams_df = pd.read_csv(MAMS_PATH)\n",
    "dep_gen_laptop = pd.read_csv(DEP_GENERATED_LAPTOP)\n",
    "mams_gen_laptop = pd.read_csv(MAMS_GENRATED_LAPTOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combined_laptop = np.vstack([mams_df.values, dep_gen_laptop.values, mams_gen_laptop.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10393, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_combined_laptop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list = []\n",
    "for text, lab_list in mams_df.values:\n",
    "    fin_lab_arr = [(lab[0], None) for lab in ast.literal_eval(lab_list)]\n",
    "    ds_list.append([text, fin_lab_arr])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(ds_list, columns=['text', 'labs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv('./ds_for_generation/mams_train_in_gen_format.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c2c28cc3442c7124414bc755ca2d0f3e48a341b8e78ec1da462a20ebaa9bc9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
